{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Deep Learning using Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Package and Version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras and tensorflow have been installed in DSX\n",
    "Let's get started by importing the libraries we'll need, and check their version as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras Version: 2.0.5\n",
      "Tensor Flow Version: 1.2.1\n",
      "Python 3.5.2 |Anaconda 4.1.1 (64-bit)| (default, Jul  2 2016, 17:53:06) \n",
      "[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "import sklearn as sk\n",
    "\n",
    "\n",
    "#Check version\n",
    "print(\"Keras Version: {}\".format(keras.__version__))\n",
    "print(\"Tensor Flow Version: {}\".format(tf.__version__))\n",
    "print(\"Python {}\".format(sys.version))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful Functions for Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Several useful functions for data preprocessing, which is created by Dr.Jeff Heaton(https://www.linkedin.com/in/jeffheaton/) for his deep learning class in WashU. You can find it on Jeff's Github https://github.com/jeffheaton/t81_558_deep_learning/blob/master/jeffs_helpful.ipynb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Encode text values to dummy variables(i.e. [1,0,0],[0,1,0],[0,0,1] for red,green,blue)\n",
    "def encode_text_dummy(df, name):\n",
    "    dummies = pd.get_dummies(df[name])\n",
    "    for x in dummies.columns:\n",
    "        dummy_name = \"{}-{}\".format(name, x)\n",
    "        df[dummy_name] = dummies[x]\n",
    "    df.drop(name, axis=1, inplace=True)\n",
    "    \n",
    "# Encode text values to indexes(i.e. [1],[2],[3] for red,green,blue).\n",
    "def encode_text_index(df, name):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    df[name] = le.fit_transform(df[name])\n",
    "    return le.classes_\n",
    "\n",
    "# Convert all missing values in the specified column to the median\n",
    "def missing_median(df, name):\n",
    "    med = df[name].median()\n",
    "    df[name] = df[name].fillna(med)\n",
    "    \n",
    "# Convert a Pandas dataframe to the x,y inputs that TensorFlow needs\n",
    "def to_xy(df, target):\n",
    "    result = []\n",
    "    for x in df.columns:\n",
    "        if x != target:\n",
    "            result.append(x)\n",
    "    # find out the type of the target column.  Is it really this hard? :(\n",
    "    target_type = df[target].dtypes\n",
    "    target_type = target_type[0] if hasattr(target_type, '__iter__') else target_type\n",
    "    # Encode to int for classification, float otherwise. TensorFlow likes 32 bits.\n",
    "    if target_type in (np.int64, np.int32):\n",
    "        # Classification\n",
    "        dummies = pd.get_dummies(df[target])\n",
    "        return df.as_matrix(result).astype(np.float32), dummies.as_matrix().astype(np.float32)\n",
    "    else:\n",
    "        # Regression\n",
    "        return df.as_matrix(result).astype(np.float32), df.as_matrix([target]).astype(np.float32)\n",
    "    \n",
    "# Encode a numeric column as zscores\n",
    "def encode_numeric_zscore(df, name, mean=None, sd=None):\n",
    "    if mean is None:\n",
    "        mean = df[name].mean()\n",
    "\n",
    "    if sd is None:\n",
    "        sd = df[name].std()\n",
    "\n",
    "    df[name] = (df[name] - mean) / sd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Model using Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually, most tutorial will use two famous bench mark Auto-MPG dataset for regression and iris set for classification. Whereas, I will use Auto-MPG to do classification and iris to do regression in this demo. \n",
    "\n",
    "Auto-MPG: https://archive.ics.uci.edu/ml/datasets/auto+mpg\n",
    "iris: https://archive.ics.uci.edu/ml/datasets/iris\n",
    "\n",
    "First, let's load mpg dataset. Our intention is to classify 'cylinders' using other variables.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>year</th>\n",
       "      <th>origin</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3504</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>chevrolet chevelle malibu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3693</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>buick skylark 320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3436</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>plymouth satellite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3433</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>amc rebel sst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>3449</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>ford torino</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mpg  cylinders  displacement  horsepower  weight  acceleration  year  \\\n",
       "0  18.0          8         307.0       130.0    3504          12.0    70   \n",
       "1  15.0          8         350.0       165.0    3693          11.5    70   \n",
       "2  18.0          8         318.0       150.0    3436          11.0    70   \n",
       "3  16.0          8         304.0       150.0    3433          12.0    70   \n",
       "4  17.0          8         302.0       140.0    3449          10.5    70   \n",
       "\n",
       "   origin                       name  \n",
       "0       1  chevrolet chevelle malibu  \n",
       "1       1          buick skylark 320  \n",
       "2       1         plymouth satellite  \n",
       "3       1              amc rebel sst  \n",
       "4       1                ford torino  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "import pandas as pd\n",
    "import io\n",
    "import requests\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "url=\"https://raw.githubusercontent.com/lcx813/data/master/auto-mpg.csv\"\n",
    "df=pd.read_csv(io.StringIO(requests.get(url).content.decode('utf-8')),na_values=['NA','?'])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing and create feature vector\n",
    "missing_median(df, 'horsepower')\n",
    "\n",
    "tmp = df['name']\n",
    "df.drop('name',1,inplace=True)\n",
    "\n",
    "encode_numeric_zscore(df, 'mpg')\n",
    "encode_numeric_zscore(df, 'horsepower')\n",
    "encode_numeric_zscore(df, 'weight')\n",
    "encode_numeric_zscore(df, 'displacement')\n",
    "encode_numeric_zscore(df, 'acceleration')\n",
    "\n",
    "encode_text_dummy(df, 'origin')\n",
    "\n",
    "cylinders = encode_text_index(df, 'cylinders')\n",
    "num_classes = len(cylinders)\n",
    "\n",
    "x,y = to_xy(df,'cylinders')\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Keras to build deep neural networks. For the Keras details: https://keras.io/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "398/398 [==============================] - 0s - loss: 2.1885 - acc: 0.3668     \n",
      "Epoch 2/100\n",
      "398/398 [==============================] - 0s - loss: 1.6895 - acc: 0.5126     \n",
      "Epoch 3/100\n",
      "398/398 [==============================] - 0s - loss: 1.3730 - acc: 0.5302     \n",
      "Epoch 4/100\n",
      "398/398 [==============================] - 0s - loss: 1.1057 - acc: 0.6156     \n",
      "Epoch 5/100\n",
      "398/398 [==============================] - 0s - loss: 0.9660 - acc: 0.7211     \n",
      "Epoch 6/100\n",
      "398/398 [==============================] - 0s - loss: 0.8954 - acc: 0.7236     \n",
      "Epoch 7/100\n",
      "398/398 [==============================] - 0s - loss: 0.8484 - acc: 0.7035     \n",
      "Epoch 8/100\n",
      "398/398 [==============================] - 0s - loss: 0.8108 - acc: 0.7387     \n",
      "Epoch 9/100\n",
      "398/398 [==============================] - 0s - loss: 0.7790 - acc: 0.7538     \n",
      "Epoch 10/100\n",
      "398/398 [==============================] - 0s - loss: 0.7515 - acc: 0.7588     \n",
      "Epoch 11/100\n",
      "398/398 [==============================] - 0s - loss: 0.7243 - acc: 0.7588     \n",
      "Epoch 12/100\n",
      "398/398 [==============================] - 0s - loss: 0.6988 - acc: 0.7538     \n",
      "Epoch 13/100\n",
      "398/398 [==============================] - 0s - loss: 0.6784 - acc: 0.7613     \n",
      "Epoch 14/100\n",
      "398/398 [==============================] - 0s - loss: 0.6538 - acc: 0.7663     \n",
      "Epoch 15/100\n",
      "398/398 [==============================] - 0s - loss: 0.6323 - acc: 0.7663     \n",
      "Epoch 16/100\n",
      "398/398 [==============================] - 0s - loss: 0.6132 - acc: 0.8040     \n",
      "Epoch 17/100\n",
      "398/398 [==============================] - 0s - loss: 0.5945 - acc: 0.8417     \n",
      "Epoch 18/100\n",
      "398/398 [==============================] - 0s - loss: 0.5796 - acc: 0.8668     \n",
      "Epoch 19/100\n",
      "398/398 [==============================] - 0s - loss: 0.5646 - acc: 0.8568     \n",
      "Epoch 20/100\n",
      "398/398 [==============================] - 0s - loss: 0.5465 - acc: 0.8794     \n",
      "Epoch 21/100\n",
      "398/398 [==============================] - 0s - loss: 0.5328 - acc: 0.8744     \n",
      "Epoch 22/100\n",
      "398/398 [==============================] - 0s - loss: 0.5175 - acc: 0.9020     \n",
      "Epoch 23/100\n",
      "398/398 [==============================] - 0s - loss: 0.5054 - acc: 0.9045     \n",
      "Epoch 24/100\n",
      "398/398 [==============================] - 0s - loss: 0.4941 - acc: 0.8920     \n",
      "Epoch 25/100\n",
      "398/398 [==============================] - 0s - loss: 0.4812 - acc: 0.9070     \n",
      "Epoch 26/100\n",
      "398/398 [==============================] - 0s - loss: 0.4723 - acc: 0.9121     \n",
      "Epoch 27/100\n",
      "398/398 [==============================] - 0s - loss: 0.4632 - acc: 0.9045     \n",
      "Epoch 28/100\n",
      "398/398 [==============================] - 0s - loss: 0.4510 - acc: 0.9221     \n",
      "Epoch 29/100\n",
      "398/398 [==============================] - 0s - loss: 0.4416 - acc: 0.9271     \n",
      "Epoch 30/100\n",
      "398/398 [==============================] - 0s - loss: 0.4336 - acc: 0.9171     \n",
      "Epoch 31/100\n",
      "398/398 [==============================] - 0s - loss: 0.4261 - acc: 0.9246     \n",
      "Epoch 32/100\n",
      "398/398 [==============================] - 0s - loss: 0.4170 - acc: 0.9296     \n",
      "Epoch 33/100\n",
      "398/398 [==============================] - 0s - loss: 0.4091 - acc: 0.9271     \n",
      "Epoch 34/100\n",
      "398/398 [==============================] - 0s - loss: 0.4036 - acc: 0.9196     \n",
      "Epoch 35/100\n",
      "398/398 [==============================] - 0s - loss: 0.3945 - acc: 0.9422     \n",
      "Epoch 36/100\n",
      "398/398 [==============================] - 0s - loss: 0.3880 - acc: 0.9347     \n",
      "Epoch 37/100\n",
      "398/398 [==============================] - 0s - loss: 0.3817 - acc: 0.9296     \n",
      "Epoch 38/100\n",
      "398/398 [==============================] - 0s - loss: 0.3753 - acc: 0.9347     \n",
      "Epoch 39/100\n",
      "398/398 [==============================] - 0s - loss: 0.3701 - acc: 0.9296     \n",
      "Epoch 40/100\n",
      "398/398 [==============================] - 0s - loss: 0.3681 - acc: 0.9447     \n",
      "Epoch 41/100\n",
      "398/398 [==============================] - 0s - loss: 0.3592 - acc: 0.9322     \n",
      "Epoch 42/100\n",
      "398/398 [==============================] - 0s - loss: 0.3543 - acc: 0.9422     \n",
      "Epoch 43/100\n",
      "398/398 [==============================] - 0s - loss: 0.3471 - acc: 0.9372     \n",
      "Epoch 44/100\n",
      "398/398 [==============================] - 0s - loss: 0.3434 - acc: 0.9347     \n",
      "Epoch 45/100\n",
      "398/398 [==============================] - 0s - loss: 0.3395 - acc: 0.9497     \n",
      "Epoch 46/100\n",
      "398/398 [==============================] - 0s - loss: 0.3361 - acc: 0.9397     \n",
      "Epoch 47/100\n",
      "398/398 [==============================] - 0s - loss: 0.3321 - acc: 0.9347     \n",
      "Epoch 48/100\n",
      "398/398 [==============================] - 0s - loss: 0.3254 - acc: 0.9422     \n",
      "Epoch 49/100\n",
      "398/398 [==============================] - 0s - loss: 0.3212 - acc: 0.9397     \n",
      "Epoch 50/100\n",
      "398/398 [==============================] - 0s - loss: 0.3169 - acc: 0.9422     \n",
      "Epoch 51/100\n",
      "398/398 [==============================] - 0s - loss: 0.3155 - acc: 0.9422     \n",
      "Epoch 52/100\n",
      "398/398 [==============================] - 0s - loss: 0.3113 - acc: 0.9472     \n",
      "Epoch 53/100\n",
      "398/398 [==============================] - 0s - loss: 0.3124 - acc: 0.9347     \n",
      "Epoch 54/100\n",
      "398/398 [==============================] - 0s - loss: 0.3031 - acc: 0.9472     \n",
      "Epoch 55/100\n",
      "398/398 [==============================] - 0s - loss: 0.2990 - acc: 0.9472     \n",
      "Epoch 56/100\n",
      "398/398 [==============================] - 0s - loss: 0.2979 - acc: 0.9422     \n",
      "Epoch 57/100\n",
      "398/398 [==============================] - 0s - loss: 0.2931 - acc: 0.9472     \n",
      "Epoch 58/100\n",
      "398/398 [==============================] - 0s - loss: 0.2896 - acc: 0.9472     \n",
      "Epoch 59/100\n",
      "398/398 [==============================] - 0s - loss: 0.2869 - acc: 0.9472     \n",
      "Epoch 60/100\n",
      "398/398 [==============================] - 0s - loss: 0.2840 - acc: 0.9472     \n",
      "Epoch 61/100\n",
      "398/398 [==============================] - 0s - loss: 0.2813 - acc: 0.9472     \n",
      "Epoch 62/100\n",
      "398/398 [==============================] - 0s - loss: 0.2799 - acc: 0.9497     \n",
      "Epoch 63/100\n",
      "398/398 [==============================] - 0s - loss: 0.2750 - acc: 0.9523     \n",
      "Epoch 64/100\n",
      "398/398 [==============================] - 0s - loss: 0.2746 - acc: 0.9472     \n",
      "Epoch 65/100\n",
      "398/398 [==============================] - 0s - loss: 0.2707 - acc: 0.9447     \n",
      "Epoch 66/100\n",
      "398/398 [==============================] - 0s - loss: 0.2704 - acc: 0.9523     \n",
      "Epoch 67/100\n",
      "398/398 [==============================] - 0s - loss: 0.2687 - acc: 0.9472     \n",
      "Epoch 68/100\n",
      "398/398 [==============================] - 0s - loss: 0.2649 - acc: 0.9523     \n",
      "Epoch 69/100\n",
      "398/398 [==============================] - 0s - loss: 0.2624 - acc: 0.9497     \n",
      "Epoch 70/100\n",
      "398/398 [==============================] - 0s - loss: 0.2589 - acc: 0.9523     \n",
      "Epoch 71/100\n",
      "398/398 [==============================] - 0s - loss: 0.2572 - acc: 0.9497     \n",
      "Epoch 72/100\n",
      "398/398 [==============================] - 0s - loss: 0.2553 - acc: 0.9497     \n",
      "Epoch 73/100\n",
      "398/398 [==============================] - 0s - loss: 0.2543 - acc: 0.9472     \n",
      "Epoch 74/100\n",
      "398/398 [==============================] - 0s - loss: 0.2517 - acc: 0.9523     \n",
      "Epoch 75/100\n",
      "398/398 [==============================] - 0s - loss: 0.2490 - acc: 0.9523     \n",
      "Epoch 76/100\n",
      "398/398 [==============================] - 0s - loss: 0.2495 - acc: 0.9523     \n",
      "Epoch 77/100\n",
      "398/398 [==============================] - 0s - loss: 0.2448 - acc: 0.9497     \n",
      "Epoch 78/100\n",
      "398/398 [==============================] - 0s - loss: 0.2446 - acc: 0.9472     \n",
      "Epoch 79/100\n",
      "398/398 [==============================] - 0s - loss: 0.2415 - acc: 0.9523     \n",
      "Epoch 80/100\n",
      "398/398 [==============================] - 0s - loss: 0.2417 - acc: 0.9523     \n",
      "Epoch 81/100\n",
      "398/398 [==============================] - 0s - loss: 0.2399 - acc: 0.9523     \n",
      "Epoch 82/100\n",
      "398/398 [==============================] - 0s - loss: 0.2384 - acc: 0.9548     \n",
      "Epoch 83/100\n",
      "398/398 [==============================] - 0s - loss: 0.2366 - acc: 0.9523     \n",
      "Epoch 84/100\n",
      "398/398 [==============================] - 0s - loss: 0.2337 - acc: 0.9548     \n",
      "Epoch 85/100\n",
      "398/398 [==============================] - 0s - loss: 0.2314 - acc: 0.9523     \n",
      "Epoch 86/100\n",
      "398/398 [==============================] - 0s - loss: 0.2307 - acc: 0.9548     \n",
      "Epoch 87/100\n",
      "398/398 [==============================] - 0s - loss: 0.2297 - acc: 0.9497     \n",
      "Epoch 88/100\n",
      "398/398 [==============================] - 0s - loss: 0.2278 - acc: 0.9523     \n",
      "Epoch 89/100\n",
      "398/398 [==============================] - 0s - loss: 0.2263 - acc: 0.9523     \n",
      "Epoch 90/100\n",
      "398/398 [==============================] - 0s - loss: 0.2253 - acc: 0.9523     \n",
      "Epoch 91/100\n",
      "398/398 [==============================] - 0s - loss: 0.2241 - acc: 0.9548     \n",
      "Epoch 92/100\n",
      "398/398 [==============================] - 0s - loss: 0.2221 - acc: 0.9573     \n",
      "Epoch 93/100\n",
      "398/398 [==============================] - 0s - loss: 0.2194 - acc: 0.9573     \n",
      "Epoch 94/100\n",
      "398/398 [==============================] - 0s - loss: 0.2187 - acc: 0.9523     \n",
      "Epoch 95/100\n",
      "398/398 [==============================] - 0s - loss: 0.2178 - acc: 0.9523     \n",
      "Epoch 96/100\n",
      "398/398 [==============================] - 0s - loss: 0.2162 - acc: 0.9573     \n",
      "Epoch 97/100\n",
      "398/398 [==============================] - 0s - loss: 0.2157 - acc: 0.9523     \n",
      "Epoch 98/100\n",
      "398/398 [==============================] - 0s - loss: 0.2132 - acc: 0.9523     \n",
      "Epoch 99/100\n",
      "398/398 [==============================] - 0s - loss: 0.2121 - acc: 0.9573     \n",
      "Epoch 100/100\n",
      "398/398 [==============================] - 0s - loss: 0.2110 - acc: 0.9523     \n",
      "Accuracy = 0.90\n"
     ]
    }
   ],
   "source": [
    "# Fit neural network\n",
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=x.shape[1], kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(y.shape[1],activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[\"accuracy\"])\n",
    "model.fit(x,y,verbose=1,epochs=100)\n",
    "\n",
    "# Testing\n",
    "loss, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Accuracy = {:.2f}\".format(accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Model using Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, let's load iris dataset. Our intention is to predict 'petal_w' using other variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_l</th>\n",
       "      <th>sepal_w</th>\n",
       "      <th>petal_l</th>\n",
       "      <th>petal_w</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_l  sepal_w  petal_l  petal_w      species\n",
       "0      5.1      3.5      1.4      0.2  Iris-setosa\n",
       "1      4.9      3.0      1.4      0.2  Iris-setosa\n",
       "2      4.7      3.2      1.3      0.2  Iris-setosa\n",
       "3      4.6      3.1      1.5      0.2  Iris-setosa\n",
       "4      5.0      3.6      1.4      0.2  Iris-setosa"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "import pandas as pd\n",
    "import io\n",
    "import requests\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "url=\"https://raw.githubusercontent.com/lcx813/data/master/iris.csv\"\n",
    "df=pd.read_csv(io.StringIO(requests.get(url).content.decode('utf-8')),na_values=['NA','?'])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_text_dummy(df, 'species')\n",
    "encode_numeric_zscore(df, 'sepal_l')\n",
    "encode_numeric_zscore(df, 'sepal_w')\n",
    "encode_numeric_zscore(df, 'petal_l')\n",
    "\n",
    "x,y = to_xy(df,['petal_w'])\n",
    "train_X, test_X, train_y, test_y = train_test_split(x, y, train_size=0.8, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "0s - loss: 2.3070\n",
      "Epoch 2/100\n",
      "0s - loss: 2.2546\n",
      "Epoch 3/100\n",
      "0s - loss: 2.2028\n",
      "Epoch 4/100\n",
      "0s - loss: 2.1495\n",
      "Epoch 5/100\n",
      "0s - loss: 2.0971\n",
      "Epoch 6/100\n",
      "0s - loss: 2.0467\n",
      "Epoch 7/100\n",
      "0s - loss: 1.9955\n",
      "Epoch 8/100\n",
      "0s - loss: 1.9453\n",
      "Epoch 9/100\n",
      "0s - loss: 1.8941\n",
      "Epoch 10/100\n",
      "0s - loss: 1.8455\n",
      "Epoch 11/100\n",
      "0s - loss: 1.7944\n",
      "Epoch 12/100\n",
      "0s - loss: 1.7435\n",
      "Epoch 13/100\n",
      "0s - loss: 1.6904\n",
      "Epoch 14/100\n",
      "0s - loss: 1.6394\n",
      "Epoch 15/100\n",
      "0s - loss: 1.5847\n",
      "Epoch 16/100\n",
      "0s - loss: 1.5307\n",
      "Epoch 17/100\n",
      "0s - loss: 1.4745\n",
      "Epoch 18/100\n",
      "0s - loss: 1.4200\n",
      "Epoch 19/100\n",
      "0s - loss: 1.3650\n",
      "Epoch 20/100\n",
      "0s - loss: 1.3075\n",
      "Epoch 21/100\n",
      "0s - loss: 1.2489\n",
      "Epoch 22/100\n",
      "0s - loss: 1.1916\n",
      "Epoch 23/100\n",
      "0s - loss: 1.1299\n",
      "Epoch 24/100\n",
      "0s - loss: 1.0750\n",
      "Epoch 25/100\n",
      "0s - loss: 1.0171\n",
      "Epoch 26/100\n",
      "0s - loss: 0.9584\n",
      "Epoch 27/100\n",
      "0s - loss: 0.9012\n",
      "Epoch 28/100\n",
      "0s - loss: 0.8454\n",
      "Epoch 29/100\n",
      "0s - loss: 0.7890\n",
      "Epoch 30/100\n",
      "0s - loss: 0.7338\n",
      "Epoch 31/100\n",
      "0s - loss: 0.6821\n",
      "Epoch 32/100\n",
      "0s - loss: 0.6327\n",
      "Epoch 33/100\n",
      "0s - loss: 0.5791\n",
      "Epoch 34/100\n",
      "0s - loss: 0.5317\n",
      "Epoch 35/100\n",
      "0s - loss: 0.4865\n",
      "Epoch 36/100\n",
      "0s - loss: 0.4439\n",
      "Epoch 37/100\n",
      "0s - loss: 0.4017\n",
      "Epoch 38/100\n",
      "0s - loss: 0.3654\n",
      "Epoch 39/100\n",
      "0s - loss: 0.3277\n",
      "Epoch 40/100\n",
      "0s - loss: 0.2948\n",
      "Epoch 41/100\n",
      "0s - loss: 0.2649\n",
      "Epoch 42/100\n",
      "0s - loss: 0.2364\n",
      "Epoch 43/100\n",
      "0s - loss: 0.2119\n",
      "Epoch 44/100\n",
      "0s - loss: 0.1887\n",
      "Epoch 45/100\n",
      "0s - loss: 0.1687\n",
      "Epoch 46/100\n",
      "0s - loss: 0.1503\n",
      "Epoch 47/100\n",
      "0s - loss: 0.1366\n",
      "Epoch 48/100\n",
      "0s - loss: 0.1227\n",
      "Epoch 49/100\n",
      "0s - loss: 0.1103\n",
      "Epoch 50/100\n",
      "0s - loss: 0.1001\n",
      "Epoch 51/100\n",
      "0s - loss: 0.0919\n",
      "Epoch 52/100\n",
      "0s - loss: 0.0836\n",
      "Epoch 53/100\n",
      "0s - loss: 0.0770\n",
      "Epoch 54/100\n",
      "0s - loss: 0.0720\n",
      "Epoch 55/100\n",
      "0s - loss: 0.0670\n",
      "Epoch 56/100\n",
      "0s - loss: 0.0627\n",
      "Epoch 57/100\n",
      "0s - loss: 0.0586\n",
      "Epoch 58/100\n",
      "0s - loss: 0.0557\n",
      "Epoch 59/100\n",
      "0s - loss: 0.0532\n",
      "Epoch 60/100\n",
      "0s - loss: 0.0508\n",
      "Epoch 61/100\n",
      "0s - loss: 0.0486\n",
      "Epoch 62/100\n",
      "0s - loss: 0.0470\n",
      "Epoch 63/100\n",
      "0s - loss: 0.0454\n",
      "Epoch 64/100\n",
      "0s - loss: 0.0437\n",
      "Epoch 65/100\n",
      "0s - loss: 0.0424\n",
      "Epoch 66/100\n",
      "0s - loss: 0.0414\n",
      "Epoch 67/100\n",
      "0s - loss: 0.0403\n",
      "Epoch 68/100\n",
      "0s - loss: 0.0394\n",
      "Epoch 69/100\n",
      "0s - loss: 0.0384\n",
      "Epoch 70/100\n",
      "0s - loss: 0.0376\n",
      "Epoch 71/100\n",
      "0s - loss: 0.0368\n",
      "Epoch 72/100\n",
      "0s - loss: 0.0362\n",
      "Epoch 73/100\n",
      "0s - loss: 0.0355\n",
      "Epoch 74/100\n",
      "0s - loss: 0.0349\n",
      "Epoch 75/100\n",
      "0s - loss: 0.0344\n",
      "Epoch 76/100\n",
      "0s - loss: 0.0337\n",
      "Epoch 77/100\n",
      "0s - loss: 0.0332\n",
      "Epoch 78/100\n",
      "0s - loss: 0.0327\n",
      "Epoch 79/100\n",
      "0s - loss: 0.0323\n",
      "Epoch 80/100\n",
      "0s - loss: 0.0318\n",
      "Epoch 81/100\n",
      "0s - loss: 0.0313\n",
      "Epoch 82/100\n",
      "0s - loss: 0.0309\n",
      "Epoch 83/100\n",
      "0s - loss: 0.0305\n",
      "Epoch 84/100\n",
      "0s - loss: 0.0301\n",
      "Epoch 85/100\n",
      "0s - loss: 0.0297\n",
      "Epoch 86/100\n",
      "0s - loss: 0.0294\n",
      "Epoch 87/100\n",
      "0s - loss: 0.0290\n",
      "Epoch 88/100\n",
      "0s - loss: 0.0287\n",
      "Epoch 89/100\n",
      "0s - loss: 0.0284\n",
      "Epoch 90/100\n",
      "0s - loss: 0.0280\n",
      "Epoch 91/100\n",
      "0s - loss: 0.0277\n",
      "Epoch 92/100\n",
      "0s - loss: 0.0275\n",
      "Epoch 93/100\n",
      "0s - loss: 0.0272\n",
      "Epoch 94/100\n",
      "0s - loss: 0.0269\n",
      "Epoch 95/100\n",
      "0s - loss: 0.0266\n",
      "Epoch 96/100\n",
      "0s - loss: 0.0264\n",
      "Epoch 97/100\n",
      "0s - loss: 0.0261\n",
      "Epoch 98/100\n",
      "0s - loss: 0.0258\n",
      "Epoch 99/100\n",
      "0s - loss: 0.0255\n",
      "Epoch 100/100\n",
      "0s - loss: 0.0252\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f59006ad550>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=x.shape[1], activation='relu'))\n",
    "model.add(Dense(1, kernel_initializer='normal'))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(train_X,train_y,verbose=2,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (RMSE): 0.18683761358261108\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(test_X)\n",
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score = np.sqrt(metrics.mean_squared_error(pred,test_y))\n",
    "print(\"Final score (RMSE): {}\".format(score))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Deeper Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still use mpg dataset as an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "import pandas as pd\n",
    "import io\n",
    "import requests\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "url=\"https://raw.githubusercontent.com/lcx813/data/master/auto-mpg.csv\"\n",
    "df=pd.read_csv(io.StringIO(requests.get(url).content.decode('utf-8')),na_values=['NA','?'])\n",
    "\n",
    "# Data preprocessing and create feature vector\n",
    "missing_median(df, 'horsepower')\n",
    "\n",
    "tmp = df['name']\n",
    "df.drop('name',1,inplace=True)\n",
    "\n",
    "encode_numeric_zscore(df, 'mpg')\n",
    "encode_numeric_zscore(df, 'horsepower')\n",
    "encode_numeric_zscore(df, 'weight')\n",
    "encode_numeric_zscore(df, 'displacement')\n",
    "encode_numeric_zscore(df, 'acceleration')\n",
    "\n",
    "encode_text_dummy(df, 'origin')\n",
    "\n",
    "cylinders = encode_text_index(df, 'cylinders')\n",
    "num_classes = len(cylinders)\n",
    "\n",
    "x,y = to_xy(df,'cylinders')\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "398/398 [==============================] - 0s - loss: 1.5809 - acc: 0.5126     \n",
      "Epoch 2/100\n",
      "398/398 [==============================] - 0s - loss: 1.5381 - acc: 0.5126     \n",
      "Epoch 3/100\n",
      "398/398 [==============================] - 0s - loss: 1.4958 - acc: 0.5126     \n",
      "Epoch 4/100\n",
      "398/398 [==============================] - 0s - loss: 1.4510 - acc: 0.5126     \n",
      "Epoch 5/100\n",
      "398/398 [==============================] - 0s - loss: 1.4122 - acc: 0.5126     \n",
      "Epoch 6/100\n",
      "398/398 [==============================] - 0s - loss: 1.3674 - acc: 0.5126     \n",
      "Epoch 7/100\n",
      "398/398 [==============================] - 0s - loss: 1.3230 - acc: 0.5126     \n",
      "Epoch 8/100\n",
      "398/398 [==============================] - 0s - loss: 1.2734 - acc: 0.5126     \n",
      "Epoch 9/100\n",
      "398/398 [==============================] - 0s - loss: 1.2160 - acc: 0.5126     \n",
      "Epoch 10/100\n",
      "398/398 [==============================] - 0s - loss: 1.1579 - acc: 0.5126     \n",
      "Epoch 11/100\n",
      "398/398 [==============================] - 0s - loss: 1.1017 - acc: 0.5126     \n",
      "Epoch 12/100\n",
      "398/398 [==============================] - 0s - loss: 1.0384 - acc: 0.5126     \n",
      "Epoch 13/100\n",
      "398/398 [==============================] - 0s - loss: 0.9865 - acc: 0.5226     \n",
      "Epoch 14/100\n",
      "398/398 [==============================] - 0s - loss: 0.9278 - acc: 0.5503     \n",
      "Epoch 15/100\n",
      "398/398 [==============================] - 0s - loss: 0.8701 - acc: 0.5477     \n",
      "Epoch 16/100\n",
      "398/398 [==============================] - 0s - loss: 0.7987 - acc: 0.6030     \n",
      "Epoch 17/100\n",
      "398/398 [==============================] - 0s - loss: 0.7190 - acc: 0.6608     \n",
      "Epoch 18/100\n",
      "398/398 [==============================] - 0s - loss: 0.6506 - acc: 0.6784     \n",
      "Epoch 19/100\n",
      "398/398 [==============================] - 0s - loss: 0.5975 - acc: 0.6935     \n",
      "Epoch 20/100\n",
      "398/398 [==============================] - 0s - loss: 0.5400 - acc: 0.8819     \n",
      "Epoch 21/100\n",
      "398/398 [==============================] - 0s - loss: 0.5019 - acc: 0.9271     \n",
      "Epoch 22/100\n",
      "398/398 [==============================] - 0s - loss: 0.4729 - acc: 0.9271     \n",
      "Epoch 23/100\n",
      "398/398 [==============================] - 0s - loss: 0.4568 - acc: 0.9221     \n",
      "Epoch 24/100\n",
      "398/398 [==============================] - 0s - loss: 0.4179 - acc: 0.9372     \n",
      "Epoch 25/100\n",
      "398/398 [==============================] - 0s - loss: 0.3998 - acc: 0.9296     \n",
      "Epoch 26/100\n",
      "398/398 [==============================] - 0s - loss: 0.3789 - acc: 0.9347     \n",
      "Epoch 27/100\n",
      "398/398 [==============================] - 0s - loss: 0.3643 - acc: 0.9472     \n",
      "Epoch 28/100\n",
      "398/398 [==============================] - 0s - loss: 0.3547 - acc: 0.9397     \n",
      "Epoch 29/100\n",
      "398/398 [==============================] - 0s - loss: 0.3385 - acc: 0.9372     \n",
      "Epoch 30/100\n",
      "398/398 [==============================] - 0s - loss: 0.3322 - acc: 0.9497     \n",
      "Epoch 31/100\n",
      "398/398 [==============================] - 0s - loss: 0.3210 - acc: 0.9523     \n",
      "Epoch 32/100\n",
      "398/398 [==============================] - 0s - loss: 0.3140 - acc: 0.9497     \n",
      "Epoch 33/100\n",
      "398/398 [==============================] - 0s - loss: 0.3059 - acc: 0.9497     \n",
      "Epoch 34/100\n",
      "398/398 [==============================] - 0s - loss: 0.2963 - acc: 0.9523     \n",
      "Epoch 35/100\n",
      "398/398 [==============================] - 0s - loss: 0.3010 - acc: 0.9397     \n",
      "Epoch 36/100\n",
      "398/398 [==============================] - 0s - loss: 0.2923 - acc: 0.9497     \n",
      "Epoch 37/100\n",
      "398/398 [==============================] - 0s - loss: 0.2869 - acc: 0.9447     \n",
      "Epoch 38/100\n",
      "398/398 [==============================] - 0s - loss: 0.2791 - acc: 0.9548     \n",
      "Epoch 39/100\n",
      "398/398 [==============================] - 0s - loss: 0.2727 - acc: 0.9472     \n",
      "Epoch 40/100\n",
      "398/398 [==============================] - 0s - loss: 0.2676 - acc: 0.9523     \n",
      "Epoch 41/100\n",
      "398/398 [==============================] - 0s - loss: 0.2664 - acc: 0.9548     \n",
      "Epoch 42/100\n",
      "398/398 [==============================] - 0s - loss: 0.2557 - acc: 0.9548     \n",
      "Epoch 43/100\n",
      "398/398 [==============================] - 0s - loss: 0.2589 - acc: 0.9523     \n",
      "Epoch 44/100\n",
      "398/398 [==============================] - 0s - loss: 0.2540 - acc: 0.9548     \n",
      "Epoch 45/100\n",
      "398/398 [==============================] - 0s - loss: 0.2486 - acc: 0.9523     \n",
      "Epoch 46/100\n",
      "398/398 [==============================] - 0s - loss: 0.2442 - acc: 0.9573     \n",
      "Epoch 47/100\n",
      "398/398 [==============================] - 0s - loss: 0.2415 - acc: 0.9573     \n",
      "Epoch 48/100\n",
      "398/398 [==============================] - 0s - loss: 0.2399 - acc: 0.9523     \n",
      "Epoch 49/100\n",
      "398/398 [==============================] - 0s - loss: 0.2386 - acc: 0.9497     \n",
      "Epoch 50/100\n",
      "398/398 [==============================] - 0s - loss: 0.2314 - acc: 0.9598     \n",
      "Epoch 51/100\n",
      "398/398 [==============================] - 0s - loss: 0.2312 - acc: 0.9548     \n",
      "Epoch 52/100\n",
      "398/398 [==============================] - 0s - loss: 0.2312 - acc: 0.9573     \n",
      "Epoch 53/100\n",
      "398/398 [==============================] - 0s - loss: 0.2266 - acc: 0.9548     \n",
      "Epoch 54/100\n",
      "398/398 [==============================] - 0s - loss: 0.2219 - acc: 0.9497     \n",
      "Epoch 55/100\n",
      "398/398 [==============================] - 0s - loss: 0.2204 - acc: 0.9548     \n",
      "Epoch 56/100\n",
      "398/398 [==============================] - 0s - loss: 0.2221 - acc: 0.9598     \n",
      "Epoch 57/100\n",
      "398/398 [==============================] - 0s - loss: 0.2190 - acc: 0.9573     \n",
      "Epoch 58/100\n",
      "398/398 [==============================] - 0s - loss: 0.2134 - acc: 0.9548     \n",
      "Epoch 59/100\n",
      "398/398 [==============================] - 0s - loss: 0.2141 - acc: 0.9548     \n",
      "Epoch 60/100\n",
      "398/398 [==============================] - 0s - loss: 0.2123 - acc: 0.9598     \n",
      "Epoch 61/100\n",
      "398/398 [==============================] - 0s - loss: 0.2079 - acc: 0.9497     \n",
      "Epoch 62/100\n",
      "398/398 [==============================] - 0s - loss: 0.2132 - acc: 0.9472     \n",
      "Epoch 63/100\n",
      "398/398 [==============================] - 0s - loss: 0.2051 - acc: 0.9523     \n",
      "Epoch 64/100\n",
      "398/398 [==============================] - 0s - loss: 0.2016 - acc: 0.9598     \n",
      "Epoch 65/100\n",
      "398/398 [==============================] - 0s - loss: 0.2047 - acc: 0.9573     \n",
      "Epoch 66/100\n",
      "398/398 [==============================] - 0s - loss: 0.2028 - acc: 0.9548     \n",
      "Epoch 67/100\n",
      "398/398 [==============================] - 0s - loss: 0.2091 - acc: 0.9548     \n",
      "Epoch 68/100\n",
      "398/398 [==============================] - 0s - loss: 0.1981 - acc: 0.9523     \n",
      "Epoch 69/100\n",
      "398/398 [==============================] - 0s - loss: 0.1987 - acc: 0.9472     \n",
      "Epoch 70/100\n",
      "398/398 [==============================] - 0s - loss: 0.2059 - acc: 0.9598     \n",
      "Epoch 71/100\n",
      "398/398 [==============================] - 0s - loss: 0.2049 - acc: 0.9548     \n",
      "Epoch 72/100\n",
      "398/398 [==============================] - 0s - loss: 0.2008 - acc: 0.9523     \n",
      "Epoch 73/100\n",
      "398/398 [==============================] - 0s - loss: 0.1976 - acc: 0.9497     \n",
      "Epoch 74/100\n",
      "398/398 [==============================] - 0s - loss: 0.2091 - acc: 0.9497     \n",
      "Epoch 75/100\n",
      "398/398 [==============================] - 0s - loss: 0.2034 - acc: 0.9497     \n",
      "Epoch 76/100\n",
      "398/398 [==============================] - 0s - loss: 0.1979 - acc: 0.9472     \n",
      "Epoch 77/100\n",
      "398/398 [==============================] - 0s - loss: 0.1917 - acc: 0.9548     \n",
      "Epoch 78/100\n",
      "398/398 [==============================] - 0s - loss: 0.1856 - acc: 0.9598     \n",
      "Epoch 79/100\n",
      "398/398 [==============================] - 0s - loss: 0.1877 - acc: 0.9497     \n",
      "Epoch 80/100\n",
      "398/398 [==============================] - 0s - loss: 0.1885 - acc: 0.9548     \n",
      "Epoch 81/100\n",
      "398/398 [==============================] - 0s - loss: 0.1838 - acc: 0.9573     \n",
      "Epoch 82/100\n",
      "398/398 [==============================] - 0s - loss: 0.1890 - acc: 0.9598     \n",
      "Epoch 83/100\n",
      "398/398 [==============================] - 0s - loss: 0.1866 - acc: 0.9548     \n",
      "Epoch 84/100\n",
      "398/398 [==============================] - 0s - loss: 0.1855 - acc: 0.9523     \n",
      "Epoch 85/100\n",
      "398/398 [==============================] - 0s - loss: 0.1828 - acc: 0.9598     \n",
      "Epoch 86/100\n",
      "398/398 [==============================] - 0s - loss: 0.1781 - acc: 0.9598     \n",
      "Epoch 87/100\n",
      "398/398 [==============================] - 0s - loss: 0.1792 - acc: 0.9623     \n",
      "Epoch 88/100\n",
      "398/398 [==============================] - 0s - loss: 0.1793 - acc: 0.9598     \n",
      "Epoch 89/100\n",
      "398/398 [==============================] - 0s - loss: 0.1773 - acc: 0.9573     \n",
      "Epoch 90/100\n",
      "398/398 [==============================] - 0s - loss: 0.1779 - acc: 0.9573     \n",
      "Epoch 91/100\n",
      "398/398 [==============================] - 0s - loss: 0.1946 - acc: 0.9598     \n",
      "Epoch 92/100\n",
      "398/398 [==============================] - 0s - loss: 0.1905 - acc: 0.9523     \n",
      "Epoch 93/100\n",
      "398/398 [==============================] - 0s - loss: 0.1862 - acc: 0.9497     \n",
      "Epoch 94/100\n",
      "398/398 [==============================] - 0s - loss: 0.1801 - acc: 0.9523     \n",
      "Epoch 95/100\n",
      "398/398 [==============================] - 0s - loss: 0.1779 - acc: 0.9548     \n",
      "Epoch 96/100\n",
      "398/398 [==============================] - 0s - loss: 0.1745 - acc: 0.9548     \n",
      "Epoch 97/100\n",
      "398/398 [==============================] - 0s - loss: 0.1740 - acc: 0.9598     \n",
      "Epoch 98/100\n",
      "398/398 [==============================] - 0s - loss: 0.1830 - acc: 0.9573     \n",
      "Epoch 99/100\n",
      "398/398 [==============================] - 0s - loss: 0.1752 - acc: 0.9623     \n",
      "Epoch 100/100\n",
      "398/398 [==============================] - 0s - loss: 0.1826 - acc: 0.9573     \n",
      "Accuracy = 0.94\n"
     ]
    }
   ],
   "source": [
    "# Fit neural network\n",
    "model = Sequential()\n",
    "model.add(Dense(25, input_dim=x.shape[1], kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(15, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(10, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(y.shape[1],activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[\"accuracy\"])\n",
    "model.fit(x,y,verbose=1,epochs=100)\n",
    "\n",
    "# Testing\n",
    "loss, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Accuracy = {:.2f}\".format(accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5 (Experimental) with Spark 2.0",
   "language": "python",
   "name": "python3-spark20"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
